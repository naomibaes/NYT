{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header: ['title', 'section_name', 'snippet', 'lead_paragraph', 'year', 'month', 'web_url']\n",
      "Header has 7 columns\n",
      "Processing chunk 2000\n",
      "Processing chunk 4000\n",
      "Processing chunk 6000\n",
      "Processing chunk 8000\n",
      "Processing chunk 10000\n",
      "Number of malformed rows: 116799\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "from typing import List, Generator\n",
    "\n",
    "def read_csv_multi_char_delimiter(file_path: str, delimiter: str, chunk_size: int = 1000) -> Generator[List[List[str]], None, None]:\n",
    "    with open(file_path, 'r') as f:\n",
    "        # Escape special regex characters in the delimiter\n",
    "        escaped_delimiter = re.escape(delimiter)\n",
    "        \n",
    "        # Read and split the header\n",
    "        header = re.split(escaped_delimiter, f.readline().strip())\n",
    "        print(f\"Header: {header}\")\n",
    "        expected_column_count = len(header)\n",
    "        print(f\"Header has {expected_column_count} columns\")\n",
    "        n_malformed_rows = 0\n",
    "        chunk = []\n",
    "        working_line = ''\n",
    "        for row_num, line in enumerate(f, start=2): # Start from 2 as row 1 is header\n",
    "            working_line += line.strip('\\n')\n",
    "            row = re.split(escaped_delimiter, working_line)\n",
    "            if row[-1][0:4] != 'http':\n",
    "                #print(f\"Row {row_num} does not end with a URL\")\n",
    "                n_malformed_rows += 1\n",
    "                continue\n",
    "\n",
    "            if row[-1][0:4] == 'http' and len(row) != expected_column_count:\n",
    "                print(f\"Row {row_num} has {len(row)} columns, expected {expected_column_count}\")\n",
    "                n_malformed_rows += 1\n",
    "            \n",
    "            chunk.append(row)\n",
    "            working_line = ''\n",
    "            if len(chunk) == chunk_size:\n",
    "                yield chunk\n",
    "                chunk = []\n",
    "        print(f\"Number of malformed rows: {n_malformed_rows}\")\n",
    "        if chunk:  # Don't forget the last chunk\n",
    "            yield chunk\n",
    "\n",
    "# Usage\n",
    "file_path = 'nyt_corpus.csv'\n",
    "delimiter = '|||||'  # Replace with your actual multi-character delimiter\n",
    "chunk_size = 1000\n",
    "\n",
    "new_file_path = 'nyt_corpus_cleaned.csv'\n",
    "header = ['title', 'section_name', 'snippet', 'lead_paragraph', 'year', 'month', 'web_url']\n",
    "try:\n",
    "    with open(new_file_path, 'a') as file:\n",
    "        file.write(delimiter.join(header) + '\\n')\n",
    "    for chunk_num, chunk in enumerate(read_csv_multi_char_delimiter(file_path, delimiter, chunk_size), start=1):\n",
    "        if chunk_num % 2000 == 0:\n",
    "            print(f\"Processing chunk {chunk_num}\")\n",
    "        # check if the chunk has the correct number of columns before writing to the new file\n",
    "        for row in chunk:\n",
    "            if len(row) != 7:\n",
    "                raise ValueError(f\"Row has {len(row)} columns, expected 7\")\n",
    "        \n",
    "        string_to_write = '\\n'.join([delimiter.join(row) for row in chunk]) + '\\n'\n",
    "        with open(new_file_path, 'a') as file:\n",
    "            file.write(string_to_write)\n",
    "\n",
    "except ValueError as e:\n",
    "    print(f\"Error in CSV structure: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nyt_corpus_cleaned.csv\n",
      "Header: ['title', 'section_name', 'snippet', 'lead_paragraph', 'year', 'month', 'web_url']\n",
      "Header has 7 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "310226it [00:00, 619471.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 178254 year is 1851\n",
      "Row 178255 year is 1851\n",
      "Row 178256 year is 1851\n",
      "Row 178257 year is 1851\n",
      "Row 178258 year is 1851\n",
      "Row 178259 year is 1851\n",
      "Row 178260 year is 1851\n",
      "Row 178261 year is 1851\n",
      "Row 178262 year is 1851\n",
      "Row 178263 year is 1851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "955616it [00:01, 737826.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 731517 year is 1851\n",
      "Row 731518 year is 1851\n",
      "Row 731519 year is 1851\n",
      "Row 731520 year is 1851\n",
      "Row 731521 year is 1851\n",
      "Row 731522 year is 1851\n",
      "Row 731523 year is 1851\n",
      "Row 731524 year is 1851\n",
      "Row 731525 year is 1851\n",
      "Row 731526 year is 1851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3768875it [00:05, 756285.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3547496 year is 1851\n",
      "Row 3547497 year is 1851\n",
      "Row 3547498 year is 1851\n",
      "Row 3547499 year is 1851\n",
      "Row 3547500 year is 1851\n",
      "Row 3547501 year is 1851\n",
      "Row 3547502 year is 1851\n",
      "Row 3547503 year is 1851\n",
      "Row 3547504 year is 1851\n",
      "Row 3547505 year is 1851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4299647it [00:05, 758244.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4108563 year is 1851\n",
      "Row 4108564 year is 1851\n",
      "Row 4108565 year is 1851\n",
      "Row 4108566 year is 1851\n",
      "Row 4108567 year is 1851\n",
      "Row 4108568 year is 1851\n",
      "Row 4108569 year is 1851\n",
      "Row 4108570 year is 1851\n",
      "Row 4108571 year is 1851\n",
      "Row 4108572 year is 1851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5886700it [00:07, 743357.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5693526 year is 1851\n",
      "Row 5693527 year is 1851\n",
      "Row 5693528 year is 1851\n",
      "Row 5693529 year is 1851\n",
      "Row 5693530 year is 1851\n",
      "Row 5693531 year is 1851\n",
      "Row 5693532 year is 1851\n",
      "Row 5693533 year is 1851\n",
      "Row 5693534 year is 1851\n",
      "Row 5693535 year is 1851\n",
      "Row 5783390 year is 1851\n",
      "Row 5783391 year is 1851\n",
      "Row 5783392 year is 1851\n",
      "Row 5783393 year is 1851\n",
      "Row 5783394 year is 1851\n",
      "Row 5783395 year is 1851\n",
      "Row 5783396 year is 1851\n",
      "Row 5783397 year is 1851\n",
      "Row 5783398 year is 1851\n",
      "Row 5783399 year is 1851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6713505it [00:09, 496352.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6625761 year is not numeric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8400275it [00:12, 662047.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8234887 year is 1851\n",
      "Row 8234888 year is 1851\n",
      "Row 8234889 year is 1851\n",
      "Row 8234890 year is 1851\n",
      "Row 8234891 year is 1851\n",
      "Row 8234892 year is 1851\n",
      "Row 8234893 year is 1851\n",
      "Row 8234894 year is 1851\n",
      "Row 8234895 year is 1851\n",
      "Row 8234896 year is 1851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10002065it [00:15, 473793.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9911403 year is not numeric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10192317it [00:15, 472209.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10097873 year is not numeric\n",
      "Row 10117706 year is not numeric\n",
      "Row 10150693 year is not numeric\n",
      "Row 10189874 year is not numeric\n",
      "Row 10192507 year is not numeric\n",
      "Row 10205460 year is not numeric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10381359it [00:15, 471981.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10319355 year is not numeric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10891105it [00:16, 640705.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of malformed rows: 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# check cleaned file has no malformed rows\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "print(new_file_path)\n",
    "\n",
    "counter = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "with open(new_file_path, 'r') as f:\n",
    "    # Escape special regex characters in the delimiter\n",
    "    escaped_delimiter = re.escape(delimiter)\n",
    "    \n",
    "    # Read and split the header\n",
    "    header = re.split(escaped_delimiter, f.readline().strip())\n",
    "    print(f\"Header: {header}\")\n",
    "    expected_column_count = len(header)\n",
    "    print(f\"Header has {expected_column_count} columns\")\n",
    "    n_malformed_rows = 0\n",
    "    for row_num, line in tqdm(enumerate(f, start=2)): # Start from 2 as row 1 is header\n",
    "        row = re.split(escaped_delimiter, line)\n",
    "        # Count the number of occurrences of each value in the section_name, year, and month columns\n",
    "        for column in ['section_name', 'year', 'month']:\n",
    "            counter[column][row[header.index(column)]] += 1\n",
    "\n",
    "        # check year is numeric\n",
    "        if not row[header.index('year')].isnumeric():\n",
    "            print(f\"Row {row_num} year is not numeric\")\n",
    "            n_malformed_rows += 1\n",
    "        # check for year = 1851\n",
    "        if row[header.index('year')] == '1851':\n",
    "            print(f\"Row {row_num} year is 1851\")\n",
    "            n_malformed_rows += 1\n",
    "\n",
    "        if row[-1][0:4] != 'http':\n",
    "            print(f\"Row {row_num} does not end with a URL\")\n",
    "            n_malformed_rows += 1\n",
    "            \n",
    "        if len(row) != expected_column_count:\n",
    "            print(f\"Row {row_num} has {len(row)} columns, expected {expected_column_count}\")\n",
    "            n_malformed_rows += 1\n",
    "    print(f\"Number of malformed rows: {n_malformed_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['section_name', 'year', 'month'])\n",
      "Unique values in section_name: 91\n",
      "Top 10 most common values in section_name:\n",
      "Archives: 6997368\n",
      "Business Day: 734873\n",
      "New York: 541275\n",
      "U.S.: 366344\n",
      "Sports: 358345\n",
      "World: 321081\n",
      "Opinion: 313981\n",
      "Arts: 267545\n",
      "Style: 111235\n",
      "Books: 104160\n",
      "Unique values in year: 100\n",
      "Top 10 most common values in year:\n",
      "1936: 173408\n",
      "1937: 169383\n",
      "1941: 168840\n",
      "1930: 168794\n",
      "1935: 168559\n",
      "1934: 168145\n",
      "1931: 165195\n",
      "2006: 163382\n",
      "1951: 162577\n",
      "1950: 161566\n",
      "Unique values in month: 12\n",
      "Top 10 most common values in month:\n",
      "10: 957520\n",
      "05: 947436\n",
      "03: 937173\n",
      "01: 931721\n",
      "04: 922900\n",
      "11: 918846\n",
      "06: 900381\n",
      "07: 890903\n",
      "12: 882774\n",
      "08: 878949\n"
     ]
    }
   ],
   "source": [
    "print(counter.keys())\n",
    "\n",
    "for key in counter.keys():\n",
    "    print(f\"Unique values in {key}: {len(counter[key])}\")\n",
    "    print(f\"Top 10 most common values in {key}:\")\n",
    "    for value, count in sorted(counter[key].items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "        print(f\"{value}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['1930', '1931', '1851', '1932', '1933', '1934', '1935', '1936', '1937', '1938', '1939', '1940', '1941', '1942', '1943', '1944', '1945', '1946', '1947', '1948', '1949', '1950', '1951', '1952', '1953', '1954', '1955', '1956', '1957', '1958', '1959', '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968', '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977', '|1977', '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986', '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '|2010', '2011', '2012', '|2012', '2013', '|2013', '2014', '|2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023'])\n",
      "100\n",
      "{'1980', '2002', '2006', '1953', '1948', '1961', '1932', '1981', '|2012', '1977', '2011', '1957', '1944', '1997', '1983', '2013', '2008', '2010', '2015', '1994', '1949', '1979', '2012', '1992', '1938', '1960', '1970', '1993', '1956', '1963', '1986', '2004', '1969', '2016', '1972', '1967', '1988', '1968', '2020', '1940', '1974', '1998', '|2014', '|1977', '1989', '1851', '2021', '1936', '2001', '2019', '1945', '1990', '1955', '1996', '1976', '1952', '2023', '1951', '2007', '1959', '2017', '1975', '1999', '1984', '1962', '1947', '1941', '2009', '1971', '1954', '1991', '1950', '1978', '|2013', '1946', '1966', '2014', '1943', '1964', '2018', '1931', '1965', '|2010', '1937', '1933', '2000', '2022', '1958', '1934', '2005', '1995', '2003', '1942', '1985', '1935', '1939', '1973', '1987', '1930', '1982'}\n"
     ]
    }
   ],
   "source": [
    "print(counter['year'].keys())\n",
    "print(len(counter['year'].keys()))\n",
    "all_years_in_dataset = set(counter['year'].keys())\n",
    "print(all_years_in_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1980', '2002', '2006', '1953', '1948', '1961', '1932', '1981', '1977', '2011', '1957', '1944', '1997', '1983', '2013', '2008', '2010', '2015', '1994', '1949', '1979', '2012', '1992', '1938', '1960', '1970', '1993', '1956', '1963', '1986', '2004', '1969', '2016', '1972', '1967', '1988', '1968', '2020', '1940', '1974', '1998', '1989', '2021', '1936', '2001', '2019', '1945', '1990', '1955', '1996', '1976', '1952', '2023', '1951', '2007', '1959', '2017', '1975', '1999', '1984', '1962', '1947', '1941', '2009', '1971', '1954', '1991', '1950', '1978', '1946', '1966', '2014', '1943', '1964', '2018', '1931', '1965', '1937', '1933', '2000', '2022', '1958', '1934', '2005', '1995', '2003', '1942', '1985', '1935', '1939', '1973', '1987', '1930', '1982'}\n"
     ]
    }
   ],
   "source": [
    "years1930_2023 = set(f'{year}' for year in range(1930, 2024))\n",
    "print(years1930_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1851', '|1977', '|2010', '|2012', '|2013', '|2014'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_years_in_dataset - years1930_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NYT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
